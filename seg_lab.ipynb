{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Laborismertető\n",
    "Az Irányítástechnika és képfeldolgozás 1 laboratórium jelen mérése a mély neurális hálók segítségével megvalósított objektumszegmentálás kérdéskörét járja végig.\n",
    "\n",
    "Jelen fájl egyszerre szolgál mérésként és jegyzőkönyvként, a feltett kérdéseket ide válaszoljátok meg.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Előkészítése\n",
    "A következő cellák az aadatok előkészítését és a szükséges kisegítő osztályokat tartalmazzák."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Package-ek importálása"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "import transforms as ext_transforms\n",
    "import utils\n",
    "\n",
    "from utils import display_batch, calc_class_weights, setup_IoU\n",
    "\n",
    "import os\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import data_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Konfiguráció\n",
    "Az `args` dict foglalja össze az összes konfigurációs (hiper)paramétert\n",
    "\n",
    "#### Megjegyzés: ebben a cellában nem kell semmit implementálnotok ahhoz, hogy a kód lefusson. Azonban későbbi feladatok során szükség lehet a paraméterek megváltoztatására, azt itt tehetitek meg."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "args = {\n",
    "        \"mode\": \"train\", # choices=['train', 'test', 'full']\n",
    "        \"resume\" : False,\n",
    "        \"batch_size\" : 10,\n",
    "        \"epochs\" : 300,\n",
    "        \"lr\" : 5e-4,\n",
    "        \"lr_decay\" : .1,\n",
    "        \"lr_decay_epochs\": 100,\n",
    "        \"weight_decay\": 2e-4,\n",
    "        \"dataset_dir\" : \"data/CamVid\",\n",
    "        \"height\" : 360,\n",
    "        \"width\" : 480,\n",
    "        \"weighting\" : \"Enet\", # choices=['enet', 'mfb', 'none']\n",
    "\n",
    "        \"ignore_unlabeled\" : False, # The unlabeled class is not ignored\n",
    "        \"workers\" : 4,\n",
    "        \"print_step\" : False, # prints loss every step if turned on\n",
    "        \"imshow_batch\" : False, # Displays batch images when loading the dataset and making predictions\n",
    "        \"device\" : \"cuda\",\n",
    "\n",
    "        \"name\": \"ENet\",\n",
    "        \"save_dir\" : \"save\"\n",
    "\n",
    "     }\n",
    "\n",
    "# Fail fast if the dataset directory doesn't exist\n",
    "assert os.path.isdir(args[\"dataset_dir\"]), f'The directory {args[\"dataset_dir\"]} does not exist.'\n",
    "# Fail fast if the saving directory doesn't exist\n",
    "assert os.path.isdir(args[\"save_dir\"]), f'The directory {args[\"save_dir\"]} does not exist.'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CamVid adatbázis\n",
    "\n",
    "Az alábbi cella a CamVid adatbázis használatához szükséges rutinokat tartalmazza.\n",
    "\n",
    "### Feladatok:\n",
    "- [ ] Az `exec_transform` függvény kiegészítése\n",
    "- [ ] Horizontal random flip operátor implementálása\n",
    "- [ ] A random transzformációk reprodukálhatóságának megvalósítása _(tipp: random seed)_\n",
    "\n",
    "### Kérdések:\n",
    "- [ ] Mire kell figyelni szegmentálás során megvalósított adataugmentáció esetében?\n",
    "- [ ] Hány véletlenszám-generátort használunk? Miért annyit?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class CamVid(data.Dataset):\n",
    "    \"\"\"CamVid dataset loader where the dataset is arranged as in\n",
    "    https://github.com/alexgkendall/SegNet-Tutorial/tree/master/CamVid.\n",
    "\n",
    "\n",
    "    Keyword arguments:\n",
    "    - root_dir (``string``): Root directory path.\n",
    "    - mode (``string``): The type of dataset: 'train' for training set, 'val'\n",
    "    for validation set, and 'test' for test set.\n",
    "    - transform (``callable``, optional): A function/transform that  takes in\n",
    "    an PIL image and returns a transformed version. Default: None.\n",
    "    - label_transform (``callable``, optional): A function/transform that takes\n",
    "    in the target and transforms it. Default: None.\n",
    "    - loader (``callable``, optional): A function to load an image given its\n",
    "    path. By default ``default_loader`` is used.\n",
    "\n",
    "    \"\"\"\n",
    "    # Training dataset root folders\n",
    "    train_folder = 'train'\n",
    "    train_lbl_folder = 'trainannot'\n",
    "\n",
    "    # Validation dataset root folders\n",
    "    val_folder = 'val'\n",
    "    val_lbl_folder = 'valannot'\n",
    "\n",
    "    # Test dataset root folders\n",
    "    test_folder = 'test'\n",
    "    test_lbl_folder = 'testannot'\n",
    "\n",
    "    # Images extension\n",
    "    img_extension = '.png'\n",
    "\n",
    "    # Default encoding for pixel value, class name, and class color\n",
    "    color_encoding = OrderedDict([\n",
    "        ('sky', (128, 128, 128)),\n",
    "        ('building', (128, 0, 0)),\n",
    "        ('pole', (192, 192, 128)),\n",
    "        ('road_marking', (255, 69, 0)),\n",
    "        ('road', (128, 64, 128)),\n",
    "        ('pavement', (60, 40, 222)),\n",
    "        ('tree', (128, 128, 0)),\n",
    "        ('sign_symbol', (192, 128, 128)),\n",
    "        ('fence', (64, 64, 128)),\n",
    "        ('car', (64, 0, 128)),\n",
    "        ('pedestrian', (64, 64, 0)),\n",
    "        ('bicyclist', (0, 128, 192)),\n",
    "        ('unlabeled', (0, 0, 0))\n",
    "    ])\n",
    "\n",
    "    def __init__(self,\n",
    "                 root_dir,\n",
    "                 mode='train',\n",
    "                 transform=None,\n",
    "                 label_transform=None,\n",
    "                 loader=data_utils.pil_loader):\n",
    "        self.root_dir = root_dir\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.label_transform = label_transform\n",
    "        self.loader = loader\n",
    "\n",
    "        if self.mode.lower() == 'train':\n",
    "            # Get the training data and labels filepaths\n",
    "            self.train_data = data_utils.get_files(\n",
    "                os.path.join(root_dir, self.train_folder),\n",
    "                extension_filter=self.img_extension)\n",
    "\n",
    "            self.train_labels = data_utils.get_files(\n",
    "                os.path.join(root_dir, self.train_lbl_folder),\n",
    "                extension_filter=self.img_extension)\n",
    "        elif self.mode.lower() == 'val':\n",
    "            # Get the validation data and labels filepaths\n",
    "            self.val_data = data_utils.get_files(\n",
    "                os.path.join(root_dir, self.val_folder),\n",
    "                extension_filter=self.img_extension)\n",
    "\n",
    "            self.val_labels = data_utils.get_files(\n",
    "                os.path.join(root_dir, self.val_lbl_folder),\n",
    "                extension_filter=self.img_extension)\n",
    "        elif self.mode.lower() == 'test':\n",
    "            # Get the test data and labels filepaths\n",
    "            self.test_data = data_utils.get_files(\n",
    "                os.path.join(root_dir, self.test_folder),\n",
    "                extension_filter=self.img_extension)\n",
    "\n",
    "            self.test_labels = data_utils.get_files(\n",
    "                os.path.join(root_dir, self.test_lbl_folder),\n",
    "                extension_filter=self.img_extension)\n",
    "        else:\n",
    "            raise RuntimeError(\"Unexpected dataset mode. \"\n",
    "                               \"Supported modes are: train, val and test\")\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - index (``int``): index of the item in the dataset\n",
    "\n",
    "        Returns:\n",
    "        A tuple of ``PIL.Image`` (image, label) where label is the ground-truth\n",
    "        of the image.\n",
    "\n",
    "        \"\"\"\n",
    "        if self.mode.lower() == 'train':\n",
    "            data_path, label_path = self.train_data[index], self.train_labels[\n",
    "                index]\n",
    "        elif self.mode.lower() == 'val':\n",
    "            data_path, label_path = self.val_data[index], self.val_labels[\n",
    "                index]\n",
    "        elif self.mode.lower() == 'test':\n",
    "            data_path, label_path = self.test_data[index], self.test_labels[\n",
    "                index]\n",
    "        else:\n",
    "            raise RuntimeError(\"Unexpected dataset mode. \"\n",
    "                               \"Supported modes are: train, val and test\")\n",
    "\n",
    "        img, label = self.loader(data_path, label_path)\n",
    "\n",
    "        img, label = self.exec_transform(img, label)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the length of the dataset.\"\"\"\n",
    "        if self.mode.lower() == 'train':\n",
    "            return len(self.train_data)\n",
    "        elif self.mode.lower() == 'val':\n",
    "            return len(self.val_data)\n",
    "        elif self.mode.lower() == 'test':\n",
    "            return len(self.test_data)\n",
    "        else:\n",
    "            raise RuntimeError(\"Unexpected dataset mode. \"\n",
    "                               \"Supported modes are: train, val and test\")\n",
    "\n",
    "    def exec_transform(self, img, label):\n",
    "        pass\n",
    "        # todo: Make a seed with numpy generator\n",
    "        # todo: apply this seed to img transforms\n",
    "\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # todo: apply this seed to label transforms\n",
    "\n",
    "\n",
    "        if self.label_transform is not None:\n",
    "            label = self.label_transform(label)\n",
    "\n",
    "        # todo: Random horizontal flip (with probability 0.5)\n",
    "\n",
    "\n",
    "        return img, label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Adatbázis betöltése\n",
    "Az alábbi cella felel a `DataLoader`-ek létrehozásáért.\n",
    "\n",
    "### Feladatok:\n",
    "- [ ] Hozzátok létre az adatbázisokat (train, test, validation) és a hozzájuk tartozó `DataLoader` objektumokat\n",
    "\n",
    "### Kérdések:\n",
    "- [ ] Mi a különbség az egyes `DataLoader` objektumok között (ha van)? Miért?\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    print(\"\\nLoading dataset...\\n\")\n",
    "\n",
    "\n",
    "    print(\"Dataset directory:\", args[\"dataset_dir\"])\n",
    "    print(\"Save directory:\", args[\"save_dir\"])\n",
    "\n",
    "    image_transform = transforms.Compose(\n",
    "        [transforms.Resize((args[\"height\"], args[\"width\"])),\n",
    "         transforms.ToTensor()])\n",
    "\n",
    "    label_transform = transforms.Compose([\n",
    "        transforms.Resize((args[\"height\"], args[\"width\"]), Image.NEAREST),\n",
    "        ext_transforms.PILToLongTensor()\n",
    "    ])\n",
    "\n",
    "    # todo: Create datasets and dataloaders\n",
    "    # Get selected dataset\n",
    "    # Load the training set as tensors\n",
    "    train_set = CamVid()\n",
    "    train_loader = None\n",
    "\n",
    "    # Load the validation set as tensors\n",
    "    val_set = CamVid()\n",
    "    val_loader = None\n",
    "\n",
    "    # Load the test set as tensors\n",
    "    test_set = CamVid()\n",
    "    test_loader = None\n",
    "\n",
    "    # todo: end\n",
    "\n",
    "    # Get encoding between pixel values in label images and RGB colors\n",
    "    class_encoding = train_set.color_encoding\n",
    "\n",
    "    # Remove the road_marking class from the CamVid dataset as it's merged\n",
    "    # with the road class\n",
    "    del class_encoding['road_marking']\n",
    "\n",
    "    # Print information for debugging\n",
    "    print(\"Number of classes to predict:\", len(class_encoding))\n",
    "    print(\"Runner dataset size:\", len(train_set))\n",
    "    print(\"Validation dataset size:\", len(val_set))\n",
    "\n",
    "    display_batch(args, class_encoding, test_loader, train_loader)\n",
    "\n",
    "    class_weights = calc_class_weights(args, class_encoding, train_loader)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, class_weights, class_encoding\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Epoch menedzsment\n",
    "A `Runner` osztály a tanító/tesztelési folyamat egy epochját implementálja.\n",
    "\n",
    "### Feladatok:\n",
    "- [ ] Valósítsátok meg a tanítás előtrejesztési lépését a `train_pass` függvényben\n",
    "- [ ] Valósítsátok meg a tesztelés előtrejesztési lépését a `test_pass` függvényben\n",
    "\n",
    "### Kérdések:\n",
    "- [ ] Mi a különbség a két megvalósított függvényben (ha van)? Miért?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Runner:\n",
    "    \"\"\"Performs the training of ``model`` given a training dataset data\n",
    "    loader, the optimizer, and the loss criterion.\n",
    "\n",
    "    Keyword arguments:\n",
    "    - model (``nn.Module``): the model instance to train.\n",
    "    - data_loader (``Dataloader``): Provides single or multi-process\n",
    "    iterators over the dataset.\n",
    "    - criterion (``Optimizer``): The loss criterion.\n",
    "    - metric (```Metric``): An instance specifying the metric to return.\n",
    "    - device (``torch.device``): An object representing the device on which\n",
    "    tensors are allocated.\n",
    "    - is_train (```bool```): the model mode (True = train, False = validation OR test)\n",
    "    - optim (``Optimizer``): The optimization algorithm.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, data_loader, criterion, metric, device, is_train=True, optim=None):\n",
    "        self.model = model\n",
    "        self.data_loader = data_loader\n",
    "        self.optim = optim\n",
    "        self.criterion = criterion\n",
    "        self.metric = metric\n",
    "        self.device = device\n",
    "\n",
    "        self.is_train = is_train\n",
    "\n",
    "        if self.optim is None:\n",
    "            self.is_train = False\n",
    "\n",
    "    def run_epoch(self, iteration_loss=False):\n",
    "        \"\"\"Runs an epoch of training.\n",
    "\n",
    "        Keyword arguments:\n",
    "        - iteration_loss (``bool``, optional): Prints loss at every step.\n",
    "\n",
    "        Returns:\n",
    "        - The epoch loss (float).\n",
    "\n",
    "        \"\"\"\n",
    "        self.set_model_mode()\n",
    "\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "        self.metric.reset()\n",
    "\n",
    "        for step, batch_data in enumerate(self.data_loader):\n",
    "            # Get the inputs and labels\n",
    "            inputs = batch_data[0].to(self.device)\n",
    "            labels = batch_data[1].to(self.device)\n",
    "\n",
    "            if self.is_train:\n",
    "                loss, outputs = self.train_pass(inputs, labels)\n",
    "            else:\n",
    "                loss, outputs = self.test_pass(inputs, labels)\n",
    "\n",
    "\n",
    "            \"\"\"Keep track of loss for current epoch\"\"\"\n",
    "            epoch_loss += None\n",
    "\n",
    "            # Keep track of the evaluation metric\n",
    "            self.metric.add(outputs.detach(), labels.detach())\n",
    "\n",
    "            if iteration_loss:\n",
    "                print(\"[Step: %d] Iteration loss: %.4f\" % (step, loss.item()))\n",
    "\n",
    "        return epoch_loss / len(self.data_loader), self.metric.value()\n",
    "\n",
    "    def set_model_mode(self):\n",
    "        if self.is_train:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "\n",
    "    def test_pass(self, inputs, labels):\n",
    "        loss, outputs = None, None\n",
    "\n",
    "        # todo: the below two steps should be within a clause\n",
    "        # todo: here something is needed that is specific to the test pass\n",
    "            #Forward propagation\n",
    "\n",
    "\n",
    "            #Loss computation\n",
    "\n",
    "\n",
    "        return loss, outputs\n",
    "\n",
    "    def train_pass(self, inputs, labels):\n",
    "        loss, outputs = None, None\n",
    "        # todo: Forward propagation\n",
    "\n",
    "\n",
    "        # todo: Loss computation\n",
    "\n",
    "\n",
    "        # todo: Backpropagation\n",
    "\n",
    "\n",
    "        return loss, outputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ENet\n",
    "A következő cellák tartalmazzák az ENet architektúrát."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Konvolúciós blokk\n",
    "Az ENet komponenseinek alapját képező, konvolúciót, Batch Normalization-t és aktivációt tartalmazó osztály\n",
    "\n",
    "### Feladatok:\n",
    "- [ ] Implementáljátok a konvolúciót, Batch Normalization-t és aktivációt tartalmazó osztályt\n",
    "\n",
    "### Kérdések:\n",
    "- [ ] Milyen sorrendben hívjuk meg a Batch Normalization-t és a (p)ReLU aktivációt? Van ennek jelentősége?\n",
    "- [ ] Miért nem jó jelen esetben az aktiváicót funkcionális alakban meghívni (`torch.nn.functional`) ? _Tipp: a különbséget csak PReLU esetében lehet tapasztalni, annak melyik tulajdonsága okozza a problémát?_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel, stride=1, padding=0, dilation=1, bias=True, activation=nn.ReLU()) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # todo: Create 2d conv, batch normalization, and an activation layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "        # todo: Define the forward pass\n",
    "\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bementi modul\n",
    "A bemenetet alakítja megfelelő dimenzionalitásúvá\n",
    "\n",
    "### Megjegyzés: ebben a cellában nincs feladatotok."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class InitialBlock(nn.Module):\n",
    "    \"\"\"The initial block is composed of two branches:\n",
    "    1. a main branch which performs a regular convolution with stride 2;\n",
    "    2. an extension branch which performs max-pooling.\n",
    "\n",
    "    Doing both operations in parallel and concatenating their results\n",
    "    allows for efficient downsampling and expansion. The main branch\n",
    "    outputs 13 feature maps while the extension branch outputs 3, for a\n",
    "    total of 16 feature maps after concatenation.\n",
    "\n",
    "    Keyword arguments:\n",
    "    - in_channels (int): the number of input channels.\n",
    "    - out_channels (int): the number output channels.\n",
    "    - kernel_size (int, optional): the kernel size of the filters used in\n",
    "    the convolution layer. Default: 3.\n",
    "    - padding (int, optional): zero-padding added to both sides of the\n",
    "    input. Default: 0.\n",
    "    - bias (bool, optional): Adds a learnable bias to the output if\n",
    "    ``True``. Default: False.\n",
    "    - relu (bool, optional): When ``True`` ReLU is used as the activation\n",
    "    function; otherwise, PReLU is used. Default: True.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bias=False, relu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        if relu:\n",
    "            activation = nn.ReLU\n",
    "        else:\n",
    "            activation = nn.PReLU\n",
    "\n",
    "        # Main branch - As stated above the number of output channels for this\n",
    "        # branch is the total minus 3, since the remaining channels come from\n",
    "        # the extension branch\n",
    "        self.main_branch = nn.Conv2d(in_channels, out_channels - 3, kernel_size=3, stride=2, padding=1, bias=bias)\n",
    "\n",
    "        # Extension branch\n",
    "        self.ext_branch = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "\n",
    "        # Initialize batch normalization to be used after concatenation\n",
    "        self.batch_norm = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # PReLU layer to apply after concatenating the branches\n",
    "        self.out_activation = activation()\n",
    "\n",
    "    def forward(self, x):\n",
    "        main = self.main_branch(x)\n",
    "        ext = self.ext_branch(x)\n",
    "\n",
    "        # Concatenate branches\n",
    "        out = torch.cat((main, ext), 1)\n",
    "\n",
    "        # Apply batch normalization\n",
    "        out = self.batch_norm(out)\n",
    "\n",
    "        return self.out_activation(out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RegularBottleneck\n",
    "Az ENet alapvető magasszintű építőeleme.\n",
    "\n",
    "### Feladatok:\n",
    "- [ ] Implementáljatok aszimmetrikus konvolúciót (`ext_conv2`)\n",
    "- [ ] Írjátok meg a `forward` függvényt\n",
    "\n",
    "### Kérdések:\n",
    "- [ ] Mi az előnye az aszimmetrikus konvolúciónak? El tudtok képzelni olyan helyzetet, amikor nem lehet megvalósítani?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class RegularBottleneck(nn.Module):\n",
    "    \"\"\"Regular bottlenecks are the main building block of ENet.\n",
    "    Main branch:\n",
    "    1. Shortcut connection.\n",
    "\n",
    "    Extension branch:\n",
    "    1. 1x1 convolution which decreases the number of channels by\n",
    "    ``internal_ratio``, also called a projection;\n",
    "    2. regular, dilated or asymmetric convolution;\n",
    "    3. 1x1 convolution which increases the number of channels back to\n",
    "    ``channels``, also called an expansion;\n",
    "    4. dropout as a regularizer.\n",
    "\n",
    "    Keyword arguments:\n",
    "    - channels (int): the number of input and output channels.\n",
    "    - internal_ratio (int, optional): a scale factor applied to\n",
    "    ``channels`` used to compute the number of\n",
    "    channels after the projection. eg. given ``channels`` equal to 128 and\n",
    "    internal_ratio equal to 2 the number of channels after the projection\n",
    "    is 64. Default: 4.\n",
    "    - kernel_size (int, optional): the kernel size of the filters used in\n",
    "    the convolution layer described above in item 2 of the extension\n",
    "    branch. Default: 3.\n",
    "    - padding (int, optional): zero-padding added to both sides of the\n",
    "    input. Default: 0.\n",
    "    - dilation (int, optional): spacing between kernel elements for the\n",
    "    convolution described in item 2 of the extension branch. Default: 1.\n",
    "    asymmetric (bool, optional): flags if the convolution described in\n",
    "    item 2 of the extension branch is asymmetric or not. Default: False.\n",
    "    - dropout_prob (float, optional): probability of an element to be\n",
    "    zeroed. Default: 0 (no dropout).\n",
    "    - bias (bool, optional): Adds a learnable bias to the output if\n",
    "    ``True``. Default: False.\n",
    "    - relu (bool, optional): When ``True`` ReLU is used as the activation\n",
    "    function; otherwise, PReLU is used. Default: True.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels, internal_ratio=4, kernel_size=3, padding=0, dilation=1, asymmetric=False,\n",
    "                 dropout_prob=0., bias=False, relu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Check in the internal_scale parameter is within the expected range\n",
    "        # [1, channels]\n",
    "        if internal_ratio <= 1 or internal_ratio > channels:\n",
    "            raise RuntimeError(\"Value out of range. Expected value in the \"\n",
    "                               \"interval [1, {0}], got internal_scale={1}.\"\n",
    "                               .format(channels, internal_ratio))\n",
    "\n",
    "        internal_channels = channels // internal_ratio\n",
    "\n",
    "        if relu:\n",
    "            activation = nn.ReLU\n",
    "        else:\n",
    "            activation = nn.PReLU\n",
    "\n",
    "        # Main branch - shortcut connection\n",
    "\n",
    "        # Extension branch - 1x1 convolution, followed by a regular, dilated or\n",
    "        # asymmetric convolution, followed by another 1x1 convolution, and,\n",
    "        # finally, a regularizer (spatial dropout). Number of channels is constant.\n",
    "        stride = 1\n",
    "\n",
    "        # 1x1 projection convolution\n",
    "        self.ext_conv1 = ConvBlock(channels, internal_channels, 1, stride, 0, 1, bias, activation())\n",
    "\n",
    "\n",
    "        # todo: Write the (asymmetric convolution)\n",
    "        # If the convolution is asymmetric we split the main convolution in\n",
    "        # two. Eg. for a 5x5 asymmetric convolution we have two convolution:\n",
    "        # the first is 5x1 and the second is 1x5.\n",
    "        # In the asymmetric case, padding also needs to be a tuple of two\n",
    "        # (the item corresponding to \"1\" in the kernel is always 0\n",
    "        if asymmetric:\n",
    "            self.ext_conv2 = None\n",
    "        else:\n",
    "            self.ext_conv2 = None\n",
    "\n",
    "        # 1x1 expansion convolution\n",
    "        self.ext_conv3 = ConvBlock(internal_channels, channels, 1, stride, 0, 1, bias, activation())\n",
    "\n",
    "        self.ext_regul = nn.Dropout2d(p=dropout_prob)\n",
    "\n",
    "        # PReLU layer to apply after adding the branches\n",
    "        self.out_activation = activation()\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "        # todo: Main branch shortcut\n",
    "\n",
    "        # todo: Extension branch (three convs + regularizer)\n",
    "\n",
    "        # todo: Add main and extension branches\n",
    "\n",
    "        # todo: Call the output activation\n",
    "\n",
    "        return\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DownsamplingBottleneck\n",
    "Leskálázásért felelős struktúra\n",
    "### Megjegyzés: ebben a cellában nincs semmi feladatotok."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DownsamplingBottleneck(nn.Module):\n",
    "    \"\"\"Downsampling bottlenecks further downsample the feature map size.\n",
    "\n",
    "    Main branch:\n",
    "    1. max pooling with stride 2; indices are saved to be used for\n",
    "    unpooling later.\n",
    "\n",
    "    Extension branch:\n",
    "    1. 2x2 convolution with stride 2 that decreases the number of channels\n",
    "    by ``internal_ratio``, also called a projection;\n",
    "    2. regular convolution (by default, 3x3);\n",
    "    3. 1x1 convolution which increases the number of channels to\n",
    "    ``out_channels``, also called an expansion;\n",
    "    4. dropout as a regularizer.\n",
    "\n",
    "    Keyword arguments:\n",
    "    - in_channels (int): the number of input channels.\n",
    "    - out_channels (int): the number of output channels.\n",
    "    - internal_ratio (int, optional): a scale factor applied to ``channels``\n",
    "    used to compute the number of channels after the projection. eg. given\n",
    "    ``channels`` equal to 128 and internal_ratio equal to 2 the number of\n",
    "    channels after the projection is 64. Default: 4.\n",
    "    - return_indices (bool, optional):  if ``True``, will return the max\n",
    "    indices along with the outputs. Useful when unpooling later.\n",
    "    - dropout_prob (float, optional): probability of an element to be\n",
    "    zeroed. Default: 0 (no dropout).\n",
    "    - bias (bool, optional): Adds a learnable bias to the output if\n",
    "    ``True``. Default: False.\n",
    "    - relu (bool, optional): When ``True`` ReLU is used as the activation\n",
    "    function; otherwise, PReLU is used. Default: True.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, internal_ratio=4, return_indices=False, dropout_prob=0., bias=False,\n",
    "                 relu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Store parameters that are needed later\n",
    "        self.return_indices = return_indices\n",
    "\n",
    "        # Check in the internal_scale parameter is within the expected range\n",
    "        # [1, channels]\n",
    "        if internal_ratio <= 1 or internal_ratio > in_channels:\n",
    "            raise RuntimeError(\"Value out of range. Expected value in the \"\n",
    "                               \"interval [1, {0}], got internal_scale={1}. \"\n",
    "                               .format(in_channels, internal_ratio))\n",
    "\n",
    "        internal_channels = in_channels // internal_ratio\n",
    "\n",
    "        if relu:\n",
    "            activation = nn.ReLU\n",
    "        else:\n",
    "            activation = nn.PReLU\n",
    "\n",
    "        # Main branch - max pooling followed by feature map (channels) padding\n",
    "        self.main_max1 = nn.MaxPool2d(2, stride=2, return_indices=return_indices)\n",
    "\n",
    "        # Extension branch - 2x2 convolution, followed by a regular, dilated or\n",
    "        # asymmetric convolution, followed by another 1x1 convolution. Number\n",
    "        # of channels is doubled.\n",
    "\n",
    "        # 2x2 projection convolution with stride 2\n",
    "        self.ext_conv1 = ConvBlock(in_channels, internal_channels, 2, 2, 0, 1, bias, activation())\n",
    "\n",
    "\n",
    "        # Convolution\n",
    "        self.ext_conv2 = ConvBlock(internal_channels, internal_channels, 3, 1, 1, 1, bias, activation())\n",
    "\n",
    "\n",
    "        # 1x1 expansion convolution\n",
    "        self.ext_conv3 = ConvBlock(internal_channels, out_channels, 1, 1, 0, 1, bias, activation())\n",
    "\n",
    "        self.ext_regul = nn.Dropout2d(p=dropout_prob)\n",
    "\n",
    "        # PReLU layer to apply after concatenating the branches\n",
    "        self.out_activation = activation()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Main branch shortcut\n",
    "        if self.return_indices:\n",
    "            main, max_indices = self.main_max1(x)\n",
    "        else:\n",
    "            main = self.main_max1(x)\n",
    "\n",
    "        # Extension branch\n",
    "        ext = self.ext_conv1(x)\n",
    "        ext = self.ext_conv2(ext)\n",
    "        ext = self.ext_conv3(ext)\n",
    "        ext = self.ext_regul(ext)\n",
    "\n",
    "        # Main branch channel padding\n",
    "        n, ch_ext, h, w = ext.size()\n",
    "        ch_main = main.size()[1]\n",
    "        padding = torch.zeros(n, ch_ext - ch_main, h, w)\n",
    "\n",
    "        # Before concatenating, check if main is on the CPU or GPU and\n",
    "        # convert padding accordingly\n",
    "        if main.is_cuda:\n",
    "            padding = padding.cuda()\n",
    "\n",
    "        # Concatenate\n",
    "        main = torch.cat((main, padding), 1)\n",
    "\n",
    "        # Add main and extension branches\n",
    "        out = main + ext\n",
    "\n",
    "        return self.out_activation(out), max_indices"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### UpsamplingBottleneck\n",
    "Felskálázásért felelős struktúra\n",
    "### Megjegyzés: ebben a cellában nincs semmi feladatotok."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class UpsamplingBottleneck(nn.Module):\n",
    "    \"\"\"The upsampling bottlenecks upsample the feature map resolution using max\n",
    "    pooling indices stored from the corresponding downsampling bottleneck.\n",
    "\n",
    "    Main branch:\n",
    "    1. 1x1 convolution with stride 1 that decreases the number of channels by\n",
    "    ``internal_ratio``, also called a projection;\n",
    "    2. max unpool layer using the max pool indices from the corresponding\n",
    "    downsampling max pool layer.\n",
    "\n",
    "    Extension branch:\n",
    "    1. 1x1 convolution with stride 1 that decreases the number of channels by\n",
    "    ``internal_ratio``, also called a projection;\n",
    "    2. transposed convolution (by default, 3x3);\n",
    "    3. 1x1 convolution which increases the number of channels to\n",
    "    ``out_channels``, also called an expansion;\n",
    "    4. dropout as a regularizer.\n",
    "\n",
    "    Keyword arguments:\n",
    "    - in_channels (int): the number of input channels.\n",
    "    - out_channels (int): the number of output channels.\n",
    "    - internal_ratio (int, optional): a scale factor applied to ``in_channels``\n",
    "     used to compute the number of channels after the projection. eg. given\n",
    "     ``in_channels`` equal to 128 and ``internal_ratio`` equal to 2 the number\n",
    "     of channels after the projection is 64. Default: 4.\n",
    "    - dropout_prob (float, optional): probability of an element to be zeroed.\n",
    "    Default: 0 (no dropout).\n",
    "    - bias (bool, optional): Adds a learnable bias to the output if ``True``.\n",
    "    Default: False.\n",
    "    - relu (bool, optional): When ``True`` ReLU is used as the activation\n",
    "    function; otherwise, PReLU is used. Default: True.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, internal_ratio=4, dropout_prob=0., bias=False, relu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Check in the internal_scale parameter is within the expected range\n",
    "        # [1, channels]\n",
    "        if internal_ratio <= 1 or internal_ratio > in_channels:\n",
    "            raise RuntimeError(\"Value out of range. Expected value in the \"\n",
    "                               \"interval [1, {0}], got internal_scale={1}. \"\n",
    "                               .format(in_channels, internal_ratio))\n",
    "\n",
    "        internal_channels = in_channels // internal_ratio\n",
    "\n",
    "        if relu:\n",
    "            activation = nn.ReLU\n",
    "        else:\n",
    "            activation = nn.PReLU\n",
    "\n",
    "        # Main branch - max pooling followed by feature map (channels) padding\n",
    "        self.main_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=bias),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "        # Remember that the stride is the same as the kernel_size, just like\n",
    "        # the max pooling layers\n",
    "        self.main_unpool1 = nn.MaxUnpool2d(kernel_size=2)\n",
    "\n",
    "        # Extension branch - 1x1 convolution, followed by a regular, dilated or\n",
    "        # asymmetric convolution, followed by another 1x1 convolution. Number\n",
    "        # of channels is doubled.\n",
    "\n",
    "        # 1x1 projection convolution with stride 1\n",
    "        self.ext_conv1 = ConvBlock(in_channels, internal_channels, 1, 1, 0, 1, bias, activation())\n",
    "\n",
    "\n",
    "        # Transposed convolution\n",
    "        self.ext_tconv1 = nn.ConvTranspose2d(internal_channels, internal_channels, kernel_size=2, stride=2, bias=bias)\n",
    "        self.ext_tconv1_bnorm = nn.BatchNorm2d(internal_channels)\n",
    "        self.ext_tconv1_activation = activation()\n",
    "\n",
    "        # 1x1 expansion convolution\n",
    "        self.ext_conv2 = ConvBlock(internal_channels, out_channels, 1, 1, 0, 1, bias, activation())\n",
    "\n",
    "        self.ext_regul = nn.Dropout2d(p=dropout_prob)\n",
    "\n",
    "        # PReLU layer to apply after concatenating the branches\n",
    "        self.out_activation = activation()\n",
    "\n",
    "    def forward(self, x, max_indices, output_size):\n",
    "        # Main branch shortcut\n",
    "        main = self.main_conv1(x)\n",
    "        main = self.main_unpool1(main, max_indices, output_size=output_size)\n",
    "\n",
    "        # Extension branch\n",
    "        ext = self.ext_conv1(x)\n",
    "        ext = self.ext_tconv1(ext, output_size=output_size)\n",
    "        ext = self.ext_tconv1_bnorm(ext)\n",
    "        ext = self.ext_tconv1_activation(ext)\n",
    "        ext = self.ext_conv2(ext)\n",
    "        ext = self.ext_regul(ext)\n",
    "\n",
    "        # Add main and extension branches\n",
    "        out = main + ext\n",
    "\n",
    "        return self.out_activation(out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Az ENet architektúra\n",
    "### Megjegyzés: ebben a cellában nincs semmi feladatotok."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ENet(nn.Module):\n",
    "    \"\"\"Generate the ENet model.\n",
    "\n",
    "    Keyword arguments:\n",
    "    - num_classes (int): the number of classes to segment.\n",
    "    - encoder_relu (bool, optional): When ``True`` ReLU is used as the\n",
    "    activation function in the encoder blocks/layers; otherwise, PReLU\n",
    "    is used. Default: False.\n",
    "    - decoder_relu (bool, optional): When ``True`` ReLU is used as the\n",
    "    activation function in the decoder blocks/layers; otherwise, PReLU\n",
    "    is used. Default: True.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes, encoder_relu=False, decoder_relu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.initial_block = InitialBlock(3, 16, relu=encoder_relu)\n",
    "\n",
    "        # Stage 1 - Encoder\n",
    "        self.downsample1_0 = DownsamplingBottleneck(16, 64, return_indices=True, dropout_prob=0.01, relu=encoder_relu)\n",
    "        self.regular1_1 = RegularBottleneck(64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
    "        self.regular1_2 = RegularBottleneck(64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
    "        self.regular1_3 = RegularBottleneck(64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
    "        self.regular1_4 = RegularBottleneck(64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
    "\n",
    "        # Stage 2 - Encoder\n",
    "        self.downsample2_0 = DownsamplingBottleneck(64, 128, return_indices=True, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.regular2_1 = RegularBottleneck(128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.dilated2_2 = RegularBottleneck(128, dilation=2, padding=2, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.asymmetric2_3 = RegularBottleneck(128, kernel_size=5, padding=2, asymmetric=True, dropout_prob=0.1,\n",
    "                                               relu=encoder_relu)\n",
    "        self.dilated2_4 = RegularBottleneck(128, dilation=4, padding=4, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.regular2_5 = RegularBottleneck(128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.dilated2_6 = RegularBottleneck(128, dilation=8, padding=8, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.asymmetric2_7 = RegularBottleneck(128, kernel_size=5, asymmetric=True, padding=2, dropout_prob=0.1,\n",
    "                                               relu=encoder_relu)\n",
    "        self.dilated2_8 = RegularBottleneck(128, dilation=16, padding=16, dropout_prob=0.1, relu=encoder_relu)\n",
    "\n",
    "        # Stage 3 - Encoder\n",
    "        self.regular3_0 = RegularBottleneck(128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.dilated3_1 = RegularBottleneck(128, dilation=2, padding=2, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.asymmetric3_2 = RegularBottleneck(128, kernel_size=5, padding=2, asymmetric=True, dropout_prob=0.1,\n",
    "                                               relu=encoder_relu)\n",
    "        self.dilated3_3 = RegularBottleneck(128, dilation=4, padding=4, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.regular3_4 = RegularBottleneck(128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.dilated3_5 = RegularBottleneck(128, dilation=8, padding=8, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.asymmetric3_6 = RegularBottleneck(128, kernel_size=5, asymmetric=True, padding=2, dropout_prob=0.1,\n",
    "                                               relu=encoder_relu)\n",
    "        self.dilated3_7 = RegularBottleneck(128, dilation=16, padding=16, dropout_prob=0.1, relu=encoder_relu)\n",
    "\n",
    "        # Stage 4 - Decoder\n",
    "        self.upsample4_0 = UpsamplingBottleneck(128, 64, dropout_prob=0.1, relu=decoder_relu)\n",
    "        self.regular4_1 = RegularBottleneck(64, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
    "        self.regular4_2 = RegularBottleneck(64, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
    "\n",
    "        # Stage 5 - Decoder\n",
    "        self.upsample5_0 = UpsamplingBottleneck(64, 16, dropout_prob=0.1, relu=decoder_relu)\n",
    "        self.regular5_1 = RegularBottleneck(16, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
    "        self.transposed_conv = nn.ConvTranspose2d(16, num_classes, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initial block\n",
    "        input_size = x.size()\n",
    "        x = self.initial_block(x)\n",
    "\n",
    "        # Stage 1 - Encoder\n",
    "        stage1_input_size = x.size()\n",
    "        x, max_indices1_0 = self.downsample1_0(x)\n",
    "        x = self.regular1_1(x)\n",
    "        x = self.regular1_2(x)\n",
    "        x = self.regular1_3(x)\n",
    "        x = self.regular1_4(x)\n",
    "\n",
    "        # Stage 2 - Encoder\n",
    "        stage2_input_size = x.size()\n",
    "        x, max_indices2_0 = self.downsample2_0(x)\n",
    "        x = self.regular2_1(x)\n",
    "        x = self.dilated2_2(x)\n",
    "        x = self.asymmetric2_3(x)\n",
    "        x = self.dilated2_4(x)\n",
    "        x = self.regular2_5(x)\n",
    "        x = self.dilated2_6(x)\n",
    "        x = self.asymmetric2_7(x)\n",
    "        x = self.dilated2_8(x)\n",
    "\n",
    "        # Stage 3 - Encoder\n",
    "        x = self.regular3_0(x)\n",
    "        x = self.dilated3_1(x)\n",
    "        x = self.asymmetric3_2(x)\n",
    "        x = self.dilated3_3(x)\n",
    "        x = self.regular3_4(x)\n",
    "        x = self.dilated3_5(x)\n",
    "        x = self.asymmetric3_6(x)\n",
    "        x = self.dilated3_7(x)\n",
    "\n",
    "        # Stage 4 - Decoder\n",
    "        x = self.upsample4_0(x, max_indices2_0, output_size=stage2_input_size)\n",
    "        x = self.regular4_1(x)\n",
    "        x = self.regular4_2(x)\n",
    "\n",
    "        # Stage 5 - Decoder\n",
    "        x = self.upsample5_0(x, max_indices1_0, output_size=stage1_input_size)\n",
    "        x = self.regular5_1(x)\n",
    "        x = self.transposed_conv(x, output_size=input_size)\n",
    "\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Kiértékelés"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tanító szkript\n",
    "\n",
    "A háló tanításáért felel\n",
    "\n",
    "### Feladatok:\n",
    "- [ ] hozzátok létre a modellt, valamint\n",
    "- [ ] az optimalizációs eljárást,\n",
    "- [ ] a költségfüggvényt,\n",
    "- [ ] az `lr_scheduler`-t\n",
    "- [ ] és a `Runner` objektumokat (tanításhoz és validációhoz)\n",
    "\n",
    "### Kérdések:\n",
    "- [ ] hogyan lehet az inhomogén osztályeloszlást figyelembe venni a költségfüggvényben? _(Tipp: nézzétek meg a költségfüggvény paramétereit)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train(train_loader, val_loader, class_weights, class_encoding):\n",
    "    print(\"\\nTraining...\\n\")\n",
    "\n",
    "    num_classes = len(class_encoding)\n",
    "\n",
    "    # todo: Create network and deploy to device\n",
    "    # Intialize ENet\n",
    "    model = None\n",
    "    # Check if the network architecture is correct\n",
    "    print(model)\n",
    "\n",
    "    # todo: Create criterion with weights\n",
    "    # We are going to use the CrossEntropyLoss loss function as it's most\n",
    "    # frequentely used in classification problems with multiple classes which\n",
    "    # fits the problem. This criterion  combines LogSoftMax and NLLLoss.\n",
    "    criterion = None\n",
    "\n",
    "    # todo: Create ADAM optimizer with weight decay\n",
    "    optimizer = None\n",
    "\n",
    "    # todo: Create learning rate decay scheduler (StepLR)\n",
    "    lr_updater = None\n",
    "\n",
    "    metric = setup_IoU(args, class_encoding)\n",
    "\n",
    "    # Optionally resume from a checkpoint\n",
    "    if args[\"resume\"]:\n",
    "        model, optimizer, start_epoch, best_miou = utils.load_checkpoint(\n",
    "            model, optimizer, args[\"save_dir\"], args[\"name\"])\n",
    "        print(f\"Resuming from model: Start epoch = {start_epoch} | Best mean IoU = {best_miou:.4f}\")\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        best_miou = 0\n",
    "\n",
    "\n",
    "    # todo: Create Runner objects\n",
    "    print()\n",
    "    train = None\n",
    "    val = None\n",
    "\n",
    "    for epoch in range(start_epoch, args[\"epochs\"]):\n",
    "        print(f\">>>> [Epoch: {epoch:d}] Training\")\n",
    "\n",
    "        epoch_loss, (iou, miou) = train.run_epoch(args[\"print_step\"])\n",
    "\n",
    "        print(f\">>>> [Epoch: {epoch:d}] Avg. loss: {epoch_loss:.4f} | Mean IoU: {miou:.4f}\")\n",
    "\n",
    "        if (epoch + 1) % 10 == 0 or epoch + 1 == args[\"epochs\"]:\n",
    "            print(f\">>>> [Epoch: {epoch:d}] Validation\")\n",
    "\n",
    "            loss, (iou, miou) = val.run_epoch(args[\"print_step\"])\n",
    "\n",
    "            print(f\">>>> [Epoch: {epoch:d}] Avg. loss: {loss:.4f} | Mean IoU: {miou:.4f}\")\n",
    "\n",
    "            # Print per class IoU on last epoch or if best iou\n",
    "            if epoch + 1 == args[\"epochs\"] or miou > best_miou:\n",
    "                for key, class_iou in zip(class_encoding.keys(), iou):\n",
    "                    print(f\"{key}: {class_iou:.4f}\")\n",
    "\n",
    "            # Save the model if it's the best thus far\n",
    "            if miou > best_miou:\n",
    "                print(\"\\nBest model thus far. Saving...\\n\")\n",
    "                best_miou = miou\n",
    "                utils.save_checkpoint(model, optimizer, epoch + 1, best_miou, args)\n",
    "\n",
    "        lr_updater.step()\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tesztszkript\n",
    "A tesztelést végzi\n",
    "\n",
    "### Megjegyzés: ebben a cellában nincs feladatotok."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test(model, test_loader, class_weights, class_encoding):\n",
    "    print(\"\\nTesting...\\n\")\n",
    "\n",
    "    num_classes = len(class_encoding)\n",
    "\n",
    "    # We are going to use the CrossEntropyLoss loss function as it's most\n",
    "    # frequently used in classification problems with multiple classes which\n",
    "    # fits the problem. This criterion  combines LogSoftMax and NLLLoss.\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "    metric = setup_IoU(args, class_encoding)\n",
    "\n",
    "    # Test the trained model on the test set\n",
    "    test = Runner(model, test_loader, criterion, metric, device, is_train=False)\n",
    "\n",
    "    print(\">>>> Running test dataset\")\n",
    "\n",
    "    loss, (iou, miou) = test.run_epoch(args[\"print_step\"])\n",
    "    class_iou = dict(zip(class_encoding.keys(), iou))\n",
    "\n",
    "    print(\">>>> Avg. loss: {0:.4f} | Mean IoU: {1:.4f}\".format(loss, miou))\n",
    "\n",
    "    # Print per class IoU\n",
    "    for key, class_iou in zip(class_encoding.keys(), iou):\n",
    "        print(\"{0}: {1:.4f}\".format(key, class_iou))\n",
    "\n",
    "    # Show a batch of samples and labels\n",
    "    if args[\"imshow_batch\"]:\n",
    "        print(\"A batch of predictions from the test set...\")\n",
    "        images, _ = iter(test_loader).next()\n",
    "        predict(model, images, class_encoding)\n",
    "\n",
    "\n",
    "def predict(model, images, class_encoding):\n",
    "    images = images.to(device)\n",
    "\n",
    "    # Make predictions!\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(images)\n",
    "\n",
    "    # Predictions is one-hot encoded with \"num_classes\" channels.\n",
    "    # Convert it to a single int using the indices where the maximum (1) occurs\n",
    "    _, predictions = torch.max(predictions.data, 1)\n",
    "\n",
    "    label_to_rgb = transforms.Compose([\n",
    "        ext_transforms.LongTensorToRGBPIL(class_encoding),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    color_predictions = utils.batch_transform(predictions.cpu(), label_to_rgb)\n",
    "    utils.imshow_batch(images.data.cpu(), color_predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Kiértékelési folyamat\n",
    "Ebben a cellában hívjuk meg a kiértékeléshez szükséges függvényeket\n",
    "\n",
    "### Megjegyzés: ebben a cellában nincs feladatotok."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading dataset...\n",
      "\n",
      "Dataset directory: data/CamVid\n",
      "Save directory: save\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'root_dir'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-18-4c40263b10fd>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mdevice\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"device\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mtrain_loader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mval_loader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_loader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mw_class\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mclass_encoding\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload_dataset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"mode\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlower\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32min\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;34m'train'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'full'\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-17-9d483efeb412>\u001B[0m in \u001B[0;36mload_dataset\u001B[1;34m()\u001B[0m\n\u001B[0;32m     18\u001B[0m     \u001B[1;31m# Get selected dataset\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     19\u001B[0m     \u001B[1;31m# Load the training set as tensors\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 20\u001B[1;33m     \u001B[0mtrain_set\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mCamVid\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     21\u001B[0m     \u001B[0mtrain_loader\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: __init__() missing 1 required positional argument: 'root_dir'"
     ]
    }
   ],
   "source": [
    "device = torch.device(args[\"device\"])\n",
    "\n",
    "train_loader, val_loader, test_loader, w_class, class_encoding = load_dataset()\n",
    "\n",
    "if args[\"mode\"].lower() in {'train', 'full'}:\n",
    "    model = train(train_loader, val_loader, w_class, class_encoding)\n",
    "\n",
    "if args[\"mode\"].lower() in {'test', 'full'}:\n",
    "    if args[\"mode\"].lower() == 'test':\n",
    "        # Intialize a new ENet model\n",
    "        num_classes = len(class_encoding)\n",
    "        model = ENet(num_classes).to(device)\n",
    "\n",
    "    # Initialize a optimizer just so we can retrieve the model from the\n",
    "    # checkpoint\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    # Load the previoulsy saved model state to the ENet model\n",
    "    model = utils.load_checkpoint(model, optimizer, args[\"save_dir\"], args[\"name\"])[0]\n",
    "\n",
    "    if args[\"mode\"].lower() == 'test':\n",
    "        print(model)\n",
    "\n",
    "    test(model, test_loader, w_class, class_encoding)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}